\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
%\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
%\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent

\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=25mm,
 bottom=25mm
 }

\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{enumerate}
\usepackage{arcs}
\usepackage{cancel}
\usepackage{xfrac}
\usepackage{amsthm}
\usepackage{gensymb}
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{fancyvrb}


\usepackage{listings}
\usepackage[most]{tcolorbox}
\usepackage{inconsolata}

\newtcblisting[auto counter]{sexylisting}[2][]{sharp corners, 
    fonttitle=\bfseries, colframe=gray, listing only, 
    listing options={basicstyle=\ttfamily,language=java}, 
    title=Listing \thetcbcounter: #2, #1}

%\usepackage{ctex}

%SetFonts

%SetFonts

\usepackage[inline]{asymptote}


\pagestyle{fancy}
\fancyhf{}
\lhead{\leftmark}
\cfoot{\thepage}

\title{3D Finger Motion Tracking Using Ultrasound and Millimeter-Wave Sensing}
\author{(Project Proposal)\\ \\Zifei (David) Zhong and Guangyi (Simona) Chen}
\date{February 16, 2022}							% Activate to display a given date or no date

\newcommand{\latex}{\LaTeX\xspace}


\begin{document}
\maketitle

\section{Motivation}
In recent years, the importance and application of 3D finger motion tracking technology have expanded considerably. This technology has diverse applications in virtual reality, gaming, sign language recognition, physical therapy, and other fields. By utilizing advanced sensors and algorithms, it can accurately track the movement and position of individual fingers in three-dimensional space, leading to a wide range of innovative and practical applications.

Although motion capture cameras offer precise tracking of finger motions, they suffer from privacy concerns~\cite{ref:cameraprivacy18}, which have led researchers to explore contactless sensing techniques based on mmWave or audio signals that are privacy-preserving and can be applied to dark environments or non-line-of-sight conditions. Recent research has focused on reconstructing 3D finger motion~\cite{ref:neuropose21, ref:sslotr22, ref:mm4arm23} instead of identifying hand gestures, as an approach that can successfully reconstruct 3D finger motion can solve any hand gesture identification application.

To reconstruct 3D finger motion, many proposals rely on special devices worn by users, which limits their applications. In this project, we propose to reconstruct 3D finger motion precisely based on contactless sensing with both ultrasound and millimeter-wave techniques. We believe that the fusion of ultrasound and millimeter-wave can yield fine-grained results in reconstructing 3D finger motions.

To the best of our knowledge, this is the first work to perform continuous precise 3D finger motion tracking through the fusion of ultrasound and millimeter-wave reflections.

\section{Fast Fourier Transform}
The \emph{Fast Fourier Transform} takes a time domain signal and represents it in the frequency domain. Given a target signal that is mixed from multiple sinusoidal signals (with different frequencies), the Fourier Transform helps disclose the frequency of each of the sinusoidal signals. One key assumption for Fourier Transform is that any target signal is actually a linear combination of multiple simple sinusoidal signals, e.g., 
$$x(t) = a_0 \cdot x_0(t) + a_1 \cdot x_1(t) + \cdots + a_n \cdot x_n(t),$$
where $x(t)$ is the target signal, the series $x_i(t)$ are simple sinusoidal signals, and $a_i$ is the coefficient of $x_i(t)$. The Fourier Transform simply reveals the value of each $a_i$.

\subsection{Sampling}
For the time series of a signal, we sample it in the time domain to get an array of values. There are two key factors that affects the resulted array: sampling frequency $f_s$, and duration $T_s$ of the signal in sampling. The higher sample frequency, the more samples we can get each second. The longer duration, the more samples we can get in total.

For example, given a signal with duration of 5 seconds, we sample it at the rate of 1000 Hz. We should get 1000 samples per second, and totally we should get $5\times 1000 = 5000$ samples.

In experiments, we can specify the sampling rate $f_s$ and the total number of samples $N$ that we plan to get, and then calculate $T_s = \frac{N}{f_s}$ to get the duration of the signal that we need for sampling. It's possible that there exists $i$ such that $x_i(t)$ is a sinusoidal wave with cycle duration $T_s$, and in this case the frequency of $x_i(t)$ is $\frac{1}{T_s} = \frac{f_s}{N}$, which is the lowest frequency that can be characterized by the sampling. All other higher frequencies are integer multiple of $\frac{f_s}{N}.$

To achieve better frequency resolution, we can either decrease $f_s$ or increase $N$. Increasing $N$ means we will collect more samples at given sampling frequency $f_s$. Given any $f_s$, the more samples we collect, the better frequency resolution can be characterized. However, decreasing $f_s$ is a bit counter intuitive. We should notice that if the total number of samples $N$ is fixed, with a smaller $f_s$ we require a signal with longer duration in order to collect $N$ samples in total. Therefore, no matter decreasing $f_s$ or  increasing $N$, fundamentally both requires the signal lasts for longer duration for collecting samples.

\subsection{Nyquists Frequency \& Aliasing}
According to the \emph{Nyquist Frequency} theory, to recover a signal from samples, they sampling rate should be more than twice the frequency of the target signal. In other words, with a sampling rate $f_s$, we can correctly characterize signals with frequencies less than $\sfrac{f_s}{2}$. For these signals with frequencies equal to or above $\sfrac{f_s}{2}$, FFT will result aliasing: incorrectly characterizing the frequencies to some other values.

The following Matlab code in Figure~\ref{fig:aliasing-code} can be used to calculate the aliased frequency location:
\begin{figure}[ht]
\begin{sexylisting}[colback=white]{Calculating aliased frequency location}
function f = freq_aliasing(freq, sr)
    nyquist_freq = sr / 2;

    if nyquist_freq > freq
        f = freq;
    else
        r = mod(freq, nyquist_freq);
        q = (freq - r) / nyquist_freq;

        if r > 0
            q = q + 1;
        end

        if mod(q, 2) == 0
            f = mod(q * nyquist_freq, freq);
        else
            f = nyquist_freq - mod(q * nyquist_freq, freq);
        end
    end
end
\end{sexylisting}
\caption{Code for calculating aliased frequency locations}
\label{fig:aliasing-code}
\end{figure}


\subsection{Fourier Coefficients}

The FFT is essentially to find out Fourier Coefficients. The fundamental idea is relatively easy to understand. With $N$ samples, our target signal might be consist of  $N$ different sinusoidal waves, each of which has a unique frequency $f_i (1 \le i \le N)$.



\section{Experiments}
The millimeter wave device we use for experiment is IWR1443BOOST board, with 3 transmitter and 4 receiver antennas and transmitting frequency between 76 GHz to 81 GHz.

\subsection{Experiment Parameters}

For chirp transmission, each chirp lasts for 66 us, followed by a 100 us idle period. In total, each chirp transmission costs 166 us. In each frame, we usually have 128 chirps transmitted with a single transmitter, 64 chirps with two transmitters, or 32 chirps for three transmitters. With three transmitters, each frame costs $166\times 32 = 5312$ us. Since we reserve 40 ms for each frame, the duty cycle of each frame is then $\frac{166\times 32}{40\times 1000} = 13.28\%.$ We transmit 250 frames in total, and the whole process lasts for $250 \times 40 = 10000$ ms (10 seconds).

However, the ramp-type analog-to-digital converter (also known as ramp-compare or time-base ADC) starts 6 us after the beginning of each chirp, and the useful transmission is hence $66 - 6 = 60$ us. With a frequency slope ($S$) 29.982 MHz/us, the bandwidth (maximum frequency difference) is $29.982 \times 60 = 1798.92$ MHz (the maximum bandwidth supported by the TI IWR1443BOOST board is 3959.88 MHz).

With a sampling window of 60 us, the minimum frequency difference ($\Delta f$) that can be captured is $\frac{10^6}{60} \approx 1.7\times 10^4$ Hz, which corresponds to time difference $\Delta t = \frac{\Delta f}{S} = \frac{10^6}{60\times 29.982 \times 10^6} \approx 5.6\times 10^{-4}$ us, and this corresponds a distance $\Delta d = \frac{1}{2}\cdot c\cdot \Delta t = 3\times 10^8 \times 5.6\times 10^{-4}\times 10^{-6} = 8.4\times 10^{-2}$ meters (8.4 cm). It's easy to see that the best range resolution that a device with 4G Hz bandwidth can achieve is about 4 cm.

With FMCW, the reflection chirp will be mixed with the transmitting chirp to form an intermediate frequency (IF), which has a frequency that is the difference of the frequency of the transmitting chirp and the frequency of the reflection chirp. The IF frequency ($\Delta f$) can be easily observed during an experiment, and thus we can calculate the distance of the obstacle that causes the reflection: 
$$\Delta f = S\cdot \Delta t = S\cdot \frac{2d}{c} \qquad \Rightarrow \qquad d = \frac{c}{2S}\cdot \Delta f.$$

Let's review briefly how the IF signal gets generated. On the mmWave device, there is a `mixer'  component that takes the reflected signal and the transmitting signal as inputs, and generates a mixed signal that is the \emph{multiplication} of the two input signals. Given two input signals 
$$x_1 = \cos(\omega_1 t + \phi_1) \qquad \text{and}\qquad x_2 = \cos(\omega_2 t + \phi_2),$$
the multiplied signal should be 
\begin{align*}
y = x_1 \cdot x_2  = & \cos(\omega_1 t + \phi_1) \cdot \cos(\omega_2 t + \phi_2) \\
= & \frac{1}{2}\left(\cos\left[(\omega_1 t +\phi_1)+ (\omega_2 t +\phi_2)\right]+ \cos\left[(\omega_1 t +\phi_1)- (\omega_2 t +\phi_2)\right]\right)\\
= & \frac{1}{2}\left(\cos\left[(\omega_1 +\omega_2) t + (\phi_1 +\phi_2)\right]+ \cos\left[(\omega_1 - \omega_2) t + (\phi_1 - \phi_2)\right]\right)
\end{align*}

Notice that the above resulted signal is essentially a wave with two very different frequencies: $(\omega_1 + \omega_2)$ and $(\omega_1 - \omega_2)$. In our mmWave experiments, $w_1$ and $w_2$ are frequencies between 77 GHz and 81 GHz, while the difference $(w_1 - w_2)$ is at most 4 GHz (the bandwidth of the TI IWR1443BOOST mmWave board is 4 GHz). The mixer component filters out the signal with frequency $(w_1 + w_2)$, and keeps the signal with frequency  $(w_1 - w_2)$ as the output IF signal:
$$y = \cos\left[(\omega_1 - \omega_2) t + (\phi_1 - \phi_2)\right].$$

The output IF signal has a much lower frequency and it's easier to do sampling for signal processing purposes. The IF signal has a phase of $(\phi_1 - \phi_2)$, which is the difference of the phase of the transmitting signal and the phase of the reflected signal. (Should the phase of the transmitting signal be 0?)

We have a sample rate of 10000 ksps (kilo-samples per second), and we want to have 256 samples for each chirp. Effectively, for each chirp, our sampling duration is $256\times\frac{1}{10^4\cdot 10^3}\times 10^6 = 25.6$ us. (The useful transmission of each chirp is 60 us, and sampling only lasts for 25.6 us?)

Assuming the transmitting signal is $A\cdot \cos(\omega t + )$

Start frequency: 77 GHz.

Every ADC sample is 4 byte (16-bit complex: 16-bit real part and 16-bit virtual part).


\section{Notes on IWR1443BOOST FMCW}

\begin{table}[t]
\centering
\caption{Notations}
\label{tab:notation}
\vspace{4pt}
\begin{tabular}{c|l|l}
\hline
\textbf{Symbol} & \textbf{Explanation} & \textbf{\centering Note} \\
\hline
\hline
$c$ & speed of the light & $3\times 10^8$ meters per second\\
\hline
$d$ & distance between transmitter and obstacle & \\
\hline
$\Delta t$ &signal round-trip time wrt obstacle & \\
\hline
$\Delta f$ & frequency difference of the Tx/Rx signals & \\
\hline
$f_0$ & starting frequency & 77 GHz for TI IWR1443 board \\
\hline
$T$ & chirp's duration & 60 us in our experiment \\
\hline
$S$ & frequency increase pace (slope) & 29.982 MHz/us in our experiment\\
\hline
$B$ & bandwidth of a chirp, $B=T\cdot S$ & $29.982 \times 60 = 1.79892$ GHz \\
\hline
\end{tabular}
\end{table}

\begin{figure}
\centering
\begin{asy}
unitsize(22pt);
defaultpen(linewidth(1pt));

arrowbar hookhead = Arrow(HookHead, size=7, angle=20);
arrowbar smallarrows = ArcArrows(size=4, angle=35);
pen thinline = linewidth(0.6pt);

real width = 9, height = 6;
pair a1 = (-1, 0), a2 = a1 + (width, 0);
pair b1 = (0, -1), b2= b1 + (0, height);
draw(a1 -- a2, hookhead);
draw(b1 -- b2, hookhead);
label("time", a2/2+(0,-1), S);
label(rotate(90)*"frequency", b2/2 -(1,0), W);

label("$f_0$", a1, W);

// Tx and Rx signals
pair c1 = (0,0), c2 = (3,3), c3 = (3,0), c4 = (4.5,1.5);
pair d1 = (1,0), d2 = (4,3), d3 =(4,0), d4 = (5.5,1.5);

draw(c1 -- c2 -- c3 -- c4, fuchsia);
draw(d1 -- d2 -- d3 -- d4, royalblue);

// legend
pair lb = (c4+d4)/2;
Label laR = Label("{\small Rx signal}", position=EndPoint);
draw((lb.x, lb.y+2.65)--(lb.x+1, lb.y+2.65), L=laR, royalblue);
Label laT = Label("{\small Tx signal}", position=EndPoint);
draw((lb.x, lb.y+2)--(lb.x+1, lb.y+2), L=laT, fuchsia);

// chirp duration T
Label la1 = Label("$T$", align=(0,0), position=MidPoint, filltype=Fill(white));
draw((0,-0.5) -- (c3.x, c3.y-0.5), L=la1, arrow=smallarrows, bar=Bars, p=thinline);

// Bandwith of FMCW
Label la2 = Label("$B$", align=(0,0), position=MidPoint, filltype=Fill(white));
draw ((-0.5,0) -- (-0.5, c2.y), L=la2, arrow=smallarrows, bar=Bars, p=thinline);
draw(d2 -- (0, c2.y), dotted);

// Time difference of the Tx and Rx signals
Label la3 = Label("{\small $\Delta t$}", align=(0,1));
draw((c2.x, c2.y+0.5) -- (d2.x, d2.y+0.5), L=la3, arrow=smallarrows, bar=Bars, p=thinline);

// Frequency difference of the Tx/Rx signals
draw((c2.x, c2.y-1) -- (0, c2.y-1), dotted);

pair e1 = c3+0.7*(c4-c3), e2 = e1 - (0,1);
Label la4 = Label("{\small $\Delta f$}", align=(0.6,0));
draw((0.5, c2.y-1) -- (0.5, c2.y), L=la4, arrow=smallarrows, bar=Bars, p=thinline);
\end{asy}
\caption{FMCW explanation}
\label{fig: fmcw}
\end{figure}

Let's assume the transmitting signal is $x(t) = \cos \psi (t)$, we have $$f(t) = f_0 + \frac{B}{T}\cdot t, \qquad \frac{d\psi(t)}{dt} = 2\pi\cdot f(t),$$ and thus 
$$\psi(t) = \int f(t) dt = 2\pi \int (f_0+\frac{B}{T}\cdot t) dt = 2\pi f_0\cdot t + \frac{\pi B}{T}\cdot t^2.$$
The transmitting signal is therefore
$$x(t) = \cos (2\pi f_0\cdot t + \frac{\pi B}{T}\cdot t^2).$$

In reality, taking the TI IWR1443 board as an example, the transmitting bandwidth $B$ is determined by the chirp's duration and the slope that characterizes the increasing pace of the signal. Users can specify the slope and the duration of a chirp while operating the TI IWR1443 board.

In experiment, the TI IWR1443 board transmits a signal $x(t_0)$ with frequency $f(t_0)$ to an obstacle and receives the signal bounced back from the obstacle. When the return signal arrives at the board at time $t_1$, the mixer component of the board will \emph{mix} the signal $x(t_0)$ with the transmitting signal at $t_1$, e.g., $x(t_1)$ with frequency $f(t_1)$, to generate an intermediate signal with frequency $\Delta f = f(t_1) - f(t_0)$. 

From the TI IWR1443 board, it's easy to observe the intermediate signal's frequency $\Delta f$ (it's difficult to measure the round-trip time of the signal directly), and deduce the round-trip time of the signal 
$$\Delta t = \frac{\Delta f}{S},$$
and future deduce the distance from the transmitter to the obstacle 
$$d = \frac{1}{2}\cdot \Delta t \cdot c = \frac{c}{2S}\cdot \Delta f.$$

It's important to notice that the above equation states clearly the connection between distance and frequency: $\Delta f$ is proportional to $d$.

With the chirp transmitting bandwidth $B$, transmitting time $T$, the minimum frequency that can be captured by the device is 
$$\Delta f_{min} = \frac{1}{T} = \frac{S}{B}, $$ and the minimum distance from an obstacle the device is able to capture is then 
$$d_{min} = \frac{c}{2S}\cdot \Delta f_{min} = \frac{c}{2B},$$
where bandwidth $B$ determines the minimum distance that can be captured by the device. 

When design a radar, we must have in mind the maximum distance the radar can reach to detect obstacles. Given that we know $\Delta f$ is proportional to the obstacle's distance $d$, when $d$ is large, we will get a large $\Delta f$,  which in reality should be digitalized by an ADC device with sampling rate $f_s \ge \Delta f$. In fact, the ADC sampling rate is the key factor that limits the capability of the radar. Given a sampling rate $f_{max}$, we have the maximum distance that a radar can reach is 
$$d_{max} = \frac{c}{2S}\cdot  f_{max}.$$

Essentially, the $f_{max}$ of a TI IWR1443 board is just the bandwidth $B$. The $d_{max}$ is half of the distance that the wave can travel in the duration of the chirp.

\subsection{Phase}

\begin{figure}
\centering
\begin{asy}
unitsize(24pt);
defaultpen(linewidth(1pt));
import graph;

arrowbar hookhead = Arrow(HookHead, size=7, angle=20);
arrowbar hookheads = Arrows(HookHead, size=7, angle=20);
arrowbar smallarrows = ArcArrows(size=4, angle=35);
pen thinline = linewidth(0.6pt);

real freq = 0.1, slope=0.2, theta = -pi/2, t1=1.5, height=3.5;
int len = 8;

pair o = (0,0), x1=(11,0), y1 = (0,2);
path crd1 = x1 -- o -- y1;
draw(crd1, hookheads);

path crd2 = shift((0,-height))*crd1;
draw(crd2, hookheads);

path crd3 = shift(0,-2*height)*crd1;
draw(crd3, hookheads);



real fmcw(real x) {
    return cos(2*pi*freq*x + pi*slope*x*x + theta);
}

typedef real realfunc(real);

realfunc ifwave(real delta) {
    real func(real x) {
        return cos(2*pi*(slope*delta)*x+2*pi*freq*delta);
    }
    
    return func;
}

real lstart=8, llen=0.8;

path w1 = graph(fmcw, 0, len, 400);
draw(w1, fuchsia);

Label laT = Label("{\small Tx signal}", position=EndPoint);
draw((lstart, 1.5)--(lstart+llen, 1.5), L=laT, fuchsia);

path w2 = shift((t1,-height))*w1;
draw(w2, royalblue);
Label laR = Label("{\small Rx signal}", position=EndPoint);
draw((lstart,-height+1.5)--(lstart+llen, -height+1.5), L=laR, royalblue);

path w3 = shift((t1, -2*height))*graph(ifwave(t1), 0, len, 400);
draw(w3, orange);
Label laF = Label("{\small IF signal}", position=EndPoint);
draw((lstart, -2*height+1.5)--(lstart+llen, -2*height+1.5), L=laF, orange);

draw((t1,-2*height)--(t1,1.5), dotted);

pair ph0 = (0,0);
dot(ph0);
pair ph1 = (t1, fmcw(t1));
dot(ph1);
pair ph3 = (t1, -height);
dot(ph3);
pair ph4 = (t1, ifwave(t1)(0)-2*height);
dot(ph4);

label("$t_1$", (t1, -2*height), S);
label("$t_0$", (0, -2*height), S);

label("\small $\phi(t_0)$", ph0, NW);
label("\small $\phi(t_1)$", ph1, NE);
label("\small $\phi(t_0)$", ph3, NW);
label("\small $\phi(t_1) -\phi(t_0)$", ph4, NE);

\end{asy}
\caption{Phase analysis of an IF signal}
\label{fig:phase}
\end{figure}

Given
$$x(t) = \cos(2\pi f_0 t+ \pi \cdot S\cdot t^2), \qquad \text{and}\qquad t_2 = t_1 + \Delta t,$$
we have
\begin{align*}
\phi(t_2) - \phi(t_1) &= (2\pi f_0 t_2 + \pi\cdot S\cdot t_2^2) - (2\pi f_0 t_1 + \pi\cdot S\cdot t_1^2) \\
& = \left[2\pi f_0 (t_1+\Delta t) + \pi\cdot S\cdot (t_1 + \Delta t)^2\right] - (2\pi f_0 t_1 + \pi\cdot S\cdot t_1^2) \\
& = 2\pi f_0 \Delta t + 2\pi\cdot S\cdot t_1 \cdot \Delta t + \pi \cdot S\cdot \Delta t^2\\
& = 2\pi f_0 \Delta t + 2\pi \Delta f \cdot t_1 + \pi \cdot \Delta f \cdot \Delta t \\
& \approx 2\pi f_0 \Delta t
\end{align*}

For the above equation, the first term dominates since in reality $f_0$ is at $\sim$ 10GHz level while the other two terms are $\sim \frac{1}{100}$ of the first term. 

\subsection{other notes}

As explained in the mmWave Training Series module on Range Estimation, FMCW Radar transmits a continuous ramping frequency called a chirp. The difference between the instantaneous TX frequency and the instantaneous RX frequency (the delay being proportional to the distance of the object) forms the IF signal and the frequency peaks in the IF signal correspond to the distance to the objects from the sensor. Velocity and Angle are computed by measuring the phase variation in the reflected signal. The phase variation of the signal in time gives the velocity and the phase variation in space, i.e. across the different RX antennas, gives angle of arrival.

The sensor FOV (Field of View) in Azimuth and Elevation depends upon Antenna Design. If by sweep in Azimuth and Elevation (not to be confused with the frequency sweep of the chirp signal) you meant that if there is a beam e.g. in a LIDAR system, that scans the azimuth and/or elevation, that's not the case here. The sensor gets reflection from the complete FOV (both Azimuth and Elevation) with every chirp and by performing the FFTs in sequence (Range, Doppler, and Angle) computes the 3D point Cloud returning the range, velocity and angle associated with each point.

For the IWR1443BOOST EVM, the Azimuth FOV is about 120 degrees (i.e. +/- 60 degrees) and the Elevation FOV is about 30 degrees (i.e. +/- 15 degrees). The FOV can be made narrower or wider using a different antenna design based on application requirements.


(From \url{https://publish.illinois.edu/radicaldata/}) The dataset uses an FMCW (frequency modulated continuous wave) radar. This radar has 3 transmit antennas and 4 receiving antennas. In the majority of our data, we only use 2 of the transmitting antennas on the azimuthal (horizontal) axis. Using time division multiplexing, the data can mimic a system with 1 transmitter and 8 receivers. We use custom software to collect and store the raw ADC samples.


\section{Related Work}
In recent years, there has been a growing interest in using acoustic-based sensing and machine learning techniques for hand gesture recognition. EchoFlex~\cite{ref:echoflex17} is one such system that combines ultrasound imaging and neural network techniques to classify a set of 10 discrete hand gestures with high accuracy. Researchers have also explored other ultrasound-based approaches, such as using the Micro-Doppler effect~\cite{ref:usgr19}, range-Doppler map~\cite{ref:hgr22}, machine learning~\cite{ref:mhgr18}, image corner feature detection~\cite{ref:usgdr21}, ultrasonic rangefinder~\cite{ref:ss12}, multiple receiver antenna~\cite{ref:usgr18}, or microphone array~\cite{ref:usgr17} to classify hand gestures.  Acoustic-based sensing and applications is generally discussed in~\cite{ref:absa20}. 

There are also several studies that use millimeter wave technology for hand gesture recognition. In~\cite{ref:hgrmmv21, ref:slgrmmw22}, mmWave sensing based approaches are proposed to classify a given set of hand gestures. mmASL~\cite{ref:mmasl} is a system that uses 60 GHz millimeter-wave wireless signals to perform American Sign Language (ASL) recognition, while ExASL~\cite{ref:exasl20} recognizes sentence-level ASL. DeafSpaces~\cite{ref:deafspaces21} is another millimeter-wave-based system that can classify 15 different hand gestures. 

Recent trend in hand gesture study is 3D finger motion tracking, such as NeuroPose~\cite{ref:neuropose21}, ssLOTR~\cite{ref:sslotr22}, and mm4arm~\cite{ref:mm4arm23}. In particular, mm4arm~\cite{ref:mm4arm23} tracks track 3D finger motion with a mmWave-based approach without relying on any wearables.


Overall, these studies demonstrate the potential of using different sensing modalities and machine learning techniques to develop accurate and robust hand gesture recognition systems. However, none of them take advantages of both ultrasound and mmWave techniques to achieve joint-level fine-grain finger motion tracking.

%\section{Motivation}
%Motivation: (1) ASL recognition is important, good for the community with hearing disabilities. (2) Why mobile device and mmWave technology can help? (3) Current research has %limitations. (4) we propose ultrasound + mmWave, justify the reasons (goal is to improve accuracy).

\bibliographystyle{plain}
\bibliography{reference}

\end{document} 